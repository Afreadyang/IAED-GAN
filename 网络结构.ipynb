{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:py36]","language":"python","name":"conda-env-py36-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"网络结构.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mXKR87ovZvNU"},"source":["import torch\r\n","from torch import nn\r\n","from torchsummary import summary\r\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IeedATaaExj1"},"source":["cifar"]},{"cell_type":"code","metadata":{"id":"AuE1NSbJFLDF"},"source":["def double_conv(in_channels, out_channels):\r\n","    return nn.Sequential(\r\n","        nn.Conv2d(in_channels, out_channels, 3, padding=1),\r\n","        nn.ReLU(inplace=True),\r\n","        nn.Conv2d(out_channels, out_channels, 3, padding=1),\r\n","        nn.ReLU(inplace=True)\r\n","    )   \r\n","\r\n","\r\n","class Generator1(nn.Module):\r\n","    def __init__(self, in_ch):\r\n","        super(Generator1, self).__init__()                \r\n","        self.dconv_down1 = double_conv(in_ch, 64)\r\n","        self.dconv_down2 = double_conv(64, 128)\r\n","        self.dconv_down3 = double_conv(128, 256)\r\n","        self.dconv_down4 = double_conv(256, 512)        \r\n","        self.maxpool = nn.MaxPool2d(2)\r\n","        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)                \r\n","        self.dconv_up3 = double_conv(256 + 512, 256)\r\n","        self.dconv_up2 = double_conv(128 + 256, 128)\r\n","        self.dconv_up1 = double_conv(128 + 64, 64)       \r\n","        self.conv_last = nn.Conv2d(64, in_ch, 1)\r\n","        \r\n","        \r\n","    def forward(self, x):\r\n","        conv1 = self.dconv_down1(x)\r\n","        x = self.maxpool(conv1)\r\n","        conv2 = self.dconv_down2(x)\r\n","        x = self.maxpool(conv2)      \r\n","        conv3 = self.dconv_down3(x)\r\n","        x = self.maxpool(conv3)          \r\n","        x = self.dconv_down4(x)       \r\n","        x = self.upsample(x)        \r\n","        x = torch.cat([x, conv3], dim=1)        \r\n","        x = self.dconv_up3(x)\r\n","        x = self.upsample(x)        \r\n","        x = torch.cat([x, conv2], dim=1)       \r\n","        x = self.dconv_up2(x)\r\n","        x = self.upsample(x)        \r\n","        x = torch.cat([x, conv1], dim=1)          \r\n","        x = self.dconv_up1(x)\r\n","        out = self.conv_last(x)       \r\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aluPfauJE1ZP"},"source":["mnist"]},{"cell_type":"code","metadata":{"id":"Aeg1-YUSFMCy"},"source":["def double_conv(in_channels, out_channels):\r\n","    return nn.Sequential(\r\n","        nn.Conv2d(in_channels, out_channels, 3, padding=1),\r\n","        nn.ReLU(inplace=True),\r\n","        nn.Conv2d(out_channels, out_channels, 3, padding=1),\r\n","        nn.ReLU(inplace=True)\r\n","    )   \r\n","\r\n","\r\n","class Generator2(nn.Module):\r\n","    def __init__(self, in_ch):\r\n","        super(Generator2, self).__init__()      \r\n","        self.dconv_down1 = double_conv(in_ch, 64)\r\n","        self.dconv_down2 = double_conv(64, 128)\r\n","        self.dconv_down3 = double_conv(128, 256)\r\n","        self.maxpool = nn.MaxPool2d(2)\r\n","        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \r\n","        self.dconv_up3 = double_conv(128 + 256, 128)\r\n","        self.dconv_up2 = double_conv(64 + 128, 64)    \r\n","        self.conv_last = nn.Conv2d(64, in_ch, 1)\r\n","              \r\n","    def forward(self, x):\r\n","        conv1 = self.dconv_down1(x)\r\n","        x = self.maxpool(conv1)\r\n","        conv2 = self.dconv_down2(x)\r\n","        x = self.maxpool(conv2)\r\n","        x = self.dconv_down3(x)\r\n","        x = self.upsample(x)        \r\n","        x = torch.cat([x, conv2], dim=1)\r\n","        x = self.dconv_up3(x)\r\n","        x = self.upsample(x)        \r\n","        x = torch.cat([x, conv1], dim=1)              \r\n","        x = self.dconv_up2(x)   \r\n","        out = self.conv_last(x)   \r\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DF2ymM6RFdXR"},"source":["Discriminator"]},{"cell_type":"code","metadata":{"id":"ZguWEoEyFbrE"},"source":["class Discriminator(nn.Module):\r\n","\r\n","    def __init__(self, in_ch):\r\n","        super(Discriminator, self).__init__()\r\n","        self.conv1 = nn.Conv2d(in_ch, 64, 3, stride=2)\r\n","        self.conv2 = nn.Conv2d(64, 128, 3, stride=2)\r\n","        self.bn2 = nn.BatchNorm2d(128)\r\n","        self.conv3 = nn.Conv2d(128, 256, 3, stride=2)\r\n","        self.bn3 = nn.BatchNorm2d(256)\r\n","        if in_ch == 1:\r\n","            self.fc4 = nn.Linear(1024, 1)\r\n","        else:\r\n","            self.fc4 = nn.Linear(2304, 1)\r\n","\r\n","        if in_ch == 1:\r\n","            self.fc5 = nn.Linear(1024, 10)\r\n","        else:\r\n","            self.fc5 = nn.Linear(2304, 10)\r\n","\r\n","    def forward(self, x):\r\n","        h = F.leaky_relu(self.conv1(x))\r\n","        h = F.leaky_relu(self.bn2(self.conv2(h)))\r\n","        h = F.leaky_relu(self.bn3(self.conv3(h)))\r\n","        h_out = torch.sigmoid(self.fc4(h.view(h.size(0), -1)))\r\n","        cls = self.fc5(h.view(h.size(0), -1))\r\n","        return h_out, F.softmax(cls)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EB_D856wFo-j"},"source":["Target model"]},{"cell_type":"code","metadata":{"id":"VtgYiBNMFomb"},"source":["class MnistCNN(nn.Module):\r\n","    def __init__(self):\r\n","        super(MnistCNN, self).__init__()\r\n","        self.conv1 = nn.Conv2d(1, 32, 3)\r\n","        self.conv2 = nn.Conv2d(32, 64, 3)\r\n","        self.fc3 = nn.Linear(1024, 128)\r\n","        self.fc4 = nn.Linear(128, 10)\r\n","\r\n","    def forward(self, x):\r\n","        h = F.relu(self.conv1(x))\r\n","        h = F.relu(self.conv2(h))\r\n","        h = F.dropout2d(F.max_pool2d(h, 6), p=0.25)\r\n","        h = F.dropout2d(self.fc3(h.view(h.size(0), -1)), p=0.5)\r\n","        h = self.fc4(h)\r\n","        return F.log_softmax(h,dim=1)\r\n","\r\n","\r\n","class CifarCNN(nn.Module):\r\n","    def __init__(self):\r\n","        super(CifarCNN, self).__init__()\r\n","        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\r\n","        self.bn1 = nn.BatchNorm2d(64)\r\n","        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\r\n","        self.bn2 = nn.BatchNorm2d(64)\r\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\r\n","        self.bn3 = nn.BatchNorm2d(128)\r\n","        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\r\n","        self.bn4 = nn.BatchNorm2d(128)\r\n","        self.fc5 = nn.Linear(512, 256)\r\n","        self.fc6 = nn.Linear(256, 256)\r\n","        self.fc7 = nn.Linear(256, 10)\r\n","\r\n","    def forward(self, x):\r\n","        h = F.relu(self.bn1(self.conv1(x)))\r\n","        h = F.relu(self.bn2(self.conv2(h)))\r\n","        h = F.max_pool2d(h, 4)\r\n","        h = F.relu(self.bn3(self.conv3(h)))\r\n","        h = F.relu(self.bn4(self.conv4(h)))\r\n","        h = F.max_pool2d(h, 4)\r\n","        h = F.relu(self.fc5(h.view(h.size(0), -1)))\r\n","        h = F.relu(self.fc6(h))\r\n","        h = self.fc7(h)\r\n","        return F.log_softmax(h,dim=1)"],"execution_count":null,"outputs":[]}]}